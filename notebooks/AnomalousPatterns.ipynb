{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MODULES\n",
    "# Standard library\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Third party\n",
    "from tqdm import tqdm\n",
    "\n",
    "# NOTE: Your script is not in the root directory. We must hence change the system path\n",
    "DIR = \"../\"\n",
    "os.chdir(DIR)\n",
    "sys.path.append(DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "from src.methods.utils.measure_functions_directed import *\n",
    "from src.data.graph_construction import construct_IBM_graph\n",
    "from src.utils.graph_processing import graph_community\n",
    "from src.methods.utils.neighbourhood_functions import GARG_AML_nodeselection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"HI-Small\"\n",
    "path = \"data/\"+dataset+\"_Trans.csv\"\n",
    "directed = True\n",
    "\n",
    "G = construct_IBM_graph(path=path, directed = directed)\n",
    "G_reduced = graph_community(G, 10)\n",
    "\n",
    "G_reduced_und = G_reduced.to_undirected()\n",
    "G_reduced_rev = G_reduced.reverse(copy=True)\n",
    "\n",
    "nodes = list(G_reduced.nodes)\n",
    "measure_00_list = []\n",
    "measure_01_list = []\n",
    "measure_02_list = []\n",
    "measure_10_list = []\n",
    "measure_11_list = []\n",
    "measure_12_list = []\n",
    "measure_20_list = []\n",
    "measure_21_list = []\n",
    "measure_22_list = []\n",
    "\n",
    "for node in tqdm(nodes):\n",
    "    G_ego_second_und = nx.ego_graph(G_reduced_und, node, 2) #Use both incoming and outgoing edges\n",
    "    G_ego_second = nx.subgraph(G_reduced, G_ego_second_und.nodes)\n",
    "    G_ego_second_rev = nx.ego_graph(G_reduced_rev, node, 2) #Look at the reverse graph to get the incoming edges\n",
    "\n",
    "    nodes_0, nodes_1, nodes_2, nodes_ordered = GARG_AML_nodeselection(G_ego_second, node, directed = True, G_ego_second_und = G_ego_second_und, G_ego_second_rev = G_ego_second_rev)\n",
    "\n",
    "    adj_full = nx.adjacency_matrix(G_ego_second, nodelist=nodes_ordered).toarray()\n",
    "\n",
    "    size_0 = len(nodes_0)\n",
    "    size_1 = len(nodes_1)\n",
    "    size_2 = len(nodes_2)\n",
    "\n",
    "    measure_00 = measure_00_function(adj_full, size_0)\n",
    "    measure_01 = measure_01_function(adj_full, size_0, size_1)\n",
    "    measure_02 = measure_02_function(adj_full, size_0, size_1, size_2)\n",
    "    measure_10 = measure_10_function(adj_full, size_0, size_1)\n",
    "    measure_11 = measure_11_function(adj_full, size_0, size_1)\n",
    "    measure_12 = measure_12_function(adj_full, size_0, size_1, size_2)  \n",
    "    measure_20 = measure_20_function(adj_full, size_0, size_2)\n",
    "    measure_21 = measure_21_function(adj_full, size_0, size_1, size_2)\n",
    "    measure_22 = measure_22_function(adj_full, size_2)\n",
    "\n",
    "    measure_00_list.append(measure_00)\n",
    "    measure_01_list.append(measure_01)\n",
    "    measure_02_list.append(measure_02)\n",
    "    measure_10_list.append(measure_10)\n",
    "    measure_11_list.append(measure_11)\n",
    "    measure_12_list.append(measure_12)\n",
    "    measure_20_list.append(measure_20)\n",
    "    measure_21_list.append(measure_21)\n",
    "    measure_22_list.append(measure_22)\n",
    "\n",
    "data_dict = {\n",
    "    \"node\": nodes, \n",
    "    \"measure_00\": measure_00_list,\n",
    "    \"measure_01\": measure_01_list, \n",
    "    \"measure_02\": measure_02_list,\n",
    "    \"measure_10\": measure_10_list,\n",
    "    \"measure_11\": measure_11_list,\n",
    "    \"measure_12\": measure_12_list,\n",
    "    \"measure_20\": measure_20_list,\n",
    "    \"measure_21\": measure_21_list,\n",
    "    \"measure_22\": measure_22_list,\n",
    "             }\n",
    "\n",
    "measure_df = pd.DataFrame(data_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = measure_df.drop(columns = [\"node\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = IsolationForest(random_state=1997)\n",
    "clf.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = clf.score_samples(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_scores, bins = 100)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_01 = (1-y_pred)/2\n",
    "plt.hist(y_pred_01, bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_df[\"anomaly_score\"] = y_scores\n",
    "measure_df[\"anomaly_pred\"] = y_pred_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.pattern_construction import define_ML_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_df,pattern_columns = define_ML_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laundering_from = extended_df[[\"Account\", \"Is Laundering\"]+pattern_columns].groupby(\"Account\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laundering_from.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.merge(\n",
    "left = measure_df[['node', 'anomaly_score', 'anomaly_pred']],\n",
    "right = laundering_from, \n",
    "left_on=\"node\",\n",
    "right_on=\"Account\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df_test.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the node with the highest and lowest anomaly score\n",
    "# Plot their second order ego network\n",
    "\n",
    "node_max = df_test.loc[df_test[\"anomaly_score\"].idxmax()][\"node\"]\n",
    "node_min = df_test.loc[df_test[\"anomaly_score\"].idxmin()][\"node\"]\n",
    "\n",
    "G_ego_max = nx.ego_graph(G_reduced, node_max, 2) #Use both incoming and outgoing edges\n",
    "G_ego_min = nx.ego_graph(G_reduced, node_min, 2) #Use both incoming and outgoing edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G_ego_max, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G_ego_min, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "r = df_corr[\"anomaly_score\"]['Is Laundering']\n",
    "N = len(df_test)\n",
    "t_stat = r*np.sqrt((N-2)/(1-r**2)); print(t_stat)\n",
    "\n",
    "# Two-tailed t-test\n",
    "from scipy.stats import t\n",
    "p = 2*(1-t.cdf(np.abs(t_stat), N-2)); print(p)\n",
    "if p < 0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "    print(\"There is a significant correlation between anomaly score and laundering\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")\n",
    "    print(\"There is no significant correlation between anomaly score and laundering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
