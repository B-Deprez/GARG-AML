{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MODULES\n",
    "# Standard library\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Third party\n",
    "from tqdm import tqdm\n",
    "\n",
    "# NOTE: Your script is not in the root directory. We must hence change the system path\n",
    "DIR = \"../\"\n",
    "os.chdir(DIR)\n",
    "sys.path.append(DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "from src.methods.utils.measure_functions_directed import *\n",
    "from src.data.graph_construction import construct_IBM_graph\n",
    "from src.utils.graph_processing import graph_community\n",
    "from src.methods.utils.neighbourhood_functions import GARG_AML_nodeselection\n",
    "from src.data.pattern_construction import define_ML_labels, summarise_ML_labels\n",
    "from src.methods.gargaml_scores import define_gargaml_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"HI-Small\"\n",
    "path = \"data/\"+dataset+\"_Trans.csv\"\n",
    "directed = True\n",
    "\n",
    "G = construct_IBM_graph(path=path, directed = directed)\n",
    "G_reduced = graph_community(G, 10)\n",
    "\n",
    "G_reduced_und = G_reduced.to_undirected()\n",
    "G_reduced_rev = G_reduced.reverse(copy=True)\n",
    "\n",
    "nodes = list(G_reduced.nodes)\n",
    "measure_00_list = []\n",
    "measure_01_list = []\n",
    "measure_02_list = []\n",
    "measure_10_list = []\n",
    "measure_11_list = []\n",
    "measure_12_list = []\n",
    "measure_20_list = []\n",
    "measure_21_list = []\n",
    "measure_22_list = []\n",
    "\n",
    "for node in tqdm(nodes):\n",
    "    G_ego_second_und = nx.ego_graph(G_reduced_und, node, 2) #Use both incoming and outgoing edges\n",
    "    G_ego_second = nx.subgraph(G_reduced, G_ego_second_und.nodes)\n",
    "    G_ego_second_rev = nx.ego_graph(G_reduced_rev, node, 2) #Look at the reverse graph to get the incoming edges\n",
    "\n",
    "    nodes_0, nodes_1, nodes_2, nodes_ordered = GARG_AML_nodeselection(G_ego_second, node, directed = True, G_ego_second_und = G_ego_second_und, G_ego_second_rev = G_ego_second_rev)\n",
    "\n",
    "    adj_full = nx.adjacency_matrix(G_ego_second, nodelist=nodes_ordered).toarray()\n",
    "\n",
    "    size_0 = len(nodes_0)\n",
    "    size_1 = len(nodes_1)\n",
    "    size_2 = len(nodes_2)\n",
    "\n",
    "    measure_00 = measure_00_function(adj_full, size_0)\n",
    "    measure_01 = measure_01_function(adj_full, size_0, size_1)\n",
    "    measure_02 = measure_02_function(adj_full, size_0, size_1, size_2)\n",
    "    measure_10 = measure_10_function(adj_full, size_0, size_1)\n",
    "    measure_11 = measure_11_function(adj_full, size_0, size_1)\n",
    "    measure_12 = measure_12_function(adj_full, size_0, size_1, size_2)  \n",
    "    measure_20 = measure_20_function(adj_full, size_0, size_2)\n",
    "    measure_21 = measure_21_function(adj_full, size_0, size_1, size_2)\n",
    "    measure_22 = measure_22_function(adj_full, size_2)\n",
    "\n",
    "    measure_00_list.append(measure_00[0])\n",
    "    measure_01_list.append(measure_01[0])\n",
    "    measure_02_list.append(measure_02[0])\n",
    "    measure_10_list.append(measure_10[0])\n",
    "    measure_11_list.append(measure_11[0])\n",
    "    measure_12_list.append(measure_12[0])\n",
    "    measure_20_list.append(measure_20[0])\n",
    "    measure_21_list.append(measure_21[0])\n",
    "    measure_22_list.append(measure_22[0])\n",
    "\n",
    "data_dict = {\n",
    "    \"node\": nodes, \n",
    "    \"measure_00\": measure_00_list,\n",
    "    \"measure_01\": measure_01_list, \n",
    "    \"measure_02\": measure_02_list,\n",
    "    \"measure_10\": measure_10_list,\n",
    "    \"measure_11\": measure_11_list,\n",
    "    \"measure_12\": measure_12_list,\n",
    "    \"measure_20\": measure_20_list,\n",
    "    \"measure_21\": measure_21_list,\n",
    "    \"measure_22\": measure_22_list,\n",
    "             }\n",
    "\n",
    "measure_df = pd.DataFrame(data_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = measure_df.drop(columns = [\"node\"])\n",
    "clf = IsolationForest(random_state=1997)\n",
    "clf.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X)\n",
    "y_scores = clf.score_samples(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_scores, bins = 100)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_01 = (1-y_pred)/2\n",
    "plt.hist(y_pred_01, bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_df[\"anomaly_score\"] = y_scores\n",
    "measure_df[\"anomaly_pred\"] = y_pred_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"HI-Small\"  \n",
    "directed = False\n",
    "score_type = \"basic\" # basic or weighted_average\n",
    "\n",
    "str_directed = \"directed\" if directed else \"undirected\"\n",
    "results_df_measures = pd.read_csv(\"results/\"+dataset+\"_GARGAML_\"+str_directed+\".csv\")\n",
    "\n",
    "results_df = define_gargaml_scores(results_df_measures, directed=directed, score_type=score_type)\n",
    "\n",
    "transactions_df_extended, pattern_columns = define_ML_labels(\n",
    "    path_trans = \"data/\"+dataset+\"_Trans.csv\",\n",
    "    path_patterns = \"data/\"+dataset+\"_Patterns.txt\"\n",
    ")\n",
    "\n",
    "laundering_combined, _, _ = summarise_ML_labels(transactions_df_extended,pattern_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_data = transactions_df_extended[[\"Account\", \"From Bank\"]].drop_duplicates()\n",
    "from_data.columns = [\"Account\", \"Bank\"]\n",
    "to_data = transactions_df_extended[[\"Account.1\", \"To Bank\"]].drop_duplicates()\n",
    "to_data.columns = [\"Account\", \"Bank\"]\n",
    "total_data = pd.concat([from_data, to_data], axis=0).drop_duplicates()\n",
    "total_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = \"Is Laundering\"\n",
    "laundering_combined[[column]].hist(log=True)\n",
    "\n",
    "cutoff = 0.2\n",
    "laundering_combined[\"Label\"] = ((laundering_combined[column]>cutoff)*1).values\n",
    "\n",
    "labels = []\n",
    "for node in results_df.index:\n",
    "    label = int(laundering_combined.loc[node][\"Label\"])\n",
    "    labels.append(label)\n",
    "\n",
    "results_df[\"Label\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_df[['node', 'anomaly_score', 'anomaly_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.merge(\n",
    "    left = measure_df[['node', 'anomaly_score', 'anomaly_pred']],\n",
    "    right = results_df[['node', 'Label']],\n",
    "    on = \"node\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"anomaly_score\"] = abs(df_test[\"anomaly_score\"])\n",
    "df_test[\"anomaly_score\"].hist(log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = df_test[\"anomaly_score\"]\n",
    "y_test = df_test[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.mean(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_ROC = roc_auc_score(y_test, y_pred); print(\"AUC ROC:\", AUC_ROC)\n",
    "AUC_PR = average_precision_score(y_test, y_pred); print(\"AUC PR:\", AUC_PR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the node with the highest and lowest anomaly score\n",
    "# Plot their second order ego network\n",
    "\n",
    "node_max = df_test.loc[df_test[\"anomaly_score\"].idxmax()][\"node\"]\n",
    "node_min = df_test.loc[df_test[\"anomaly_score\"].idxmin()][\"node\"]\n",
    "\n",
    "G_ego_max = nx.ego_graph(G_reduced, node_max, 2) #Use both incoming and outgoing edges\n",
    "G_ego_min = nx.ego_graph(G_reduced, node_min, 2) #Use both incoming and outgoing edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G_ego_max, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G_ego_min, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "r = df_corr[\"anomaly_score\"]['Is Laundering']\n",
    "N = len(df_test)\n",
    "t_stat = r*np.sqrt((N-2)/(1-r**2)); print(t_stat)\n",
    "\n",
    "# Two-tailed t-test\n",
    "from scipy.stats import t\n",
    "p = 2*(1-t.cdf(np.abs(t_stat), N-2)); print(p)\n",
    "if p < 0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "    print(\"There is a significant correlation between anomaly score and laundering\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")\n",
    "    print(\"There is no significant correlation between anomaly score and laundering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
